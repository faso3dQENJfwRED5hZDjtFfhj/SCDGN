{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0243e1be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T05:46:09.864303Z",
     "start_time": "2022-05-19T05:46:09.186072Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import datetime\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import scipy.stats\n",
    "\n",
    "from util import *\n",
    "from models import *\n",
    "from optimization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cd8de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T05:46:10.307979Z",
     "start_time": "2022-05-19T05:46:10.280905Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ff2c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T05:46:10.729923Z",
     "start_time": "2022-05-19T05:46:10.552280Z"
    }
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1\n",
    "cuda = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd051169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T05:46:11.229635Z",
     "start_time": "2022-05-19T05:46:11.185720Z"
    },
    "code_folding": [
     34
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    " -----------------------------------------------------------------\n",
    "| Run the code in Prepare_dataset.ipynb when re-preparing dataset.|\n",
    " -----------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "def train(config, dictBank, model_file):\n",
    "    weight_file = model_file + f\"{source_name}to{target_name}-SCDGN_retrained.pth.tar\"\n",
    "    patient = 8\n",
    "    min_ = 0.\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        if epoch %10 == 0:\n",
    "            print(\"\")\n",
    "            results = Test(Recmodel, config, dictBank)\n",
    "            print(\"[TEST] hr:{0}, ndcg:{1}\".format(results['hr'][0], results['ndcg'][0]))\n",
    "            if results['ndcg'][0] > min_:\n",
    "                torch.save(Recmodel.state_dict(), weight_file)\n",
    "                min_ = results['ndcg'][0]\n",
    "                patient = 8\n",
    "                continue\n",
    "            if results['ndcg'][0] <= min_:\n",
    "                patient = patient - 1\n",
    "            if patient == 0:\n",
    "                break\n",
    "        start = time.time()\n",
    "        aver_loss, aver_pre_loss, aver_reg_loss, aver_rec_loss, aver_res_loss = Train_on_epoch(n_users, m_items, Recmodel, config, dictBank, dictBank.tr_u)\n",
    "        end = time.time()\n",
    "        sys.stdout.write(\"\\r ||epoch:{0}||loss:{1}||pre_loss:{2}||reg_loss:{3}||rec_loss:{4}||res_loss:{5}||time:{6}\".format(epoch, \n",
    "                                                                                                           aver_loss, aver_pre_loss, aver_reg_loss, aver_rec_loss, aver_res_loss,\n",
    "                                                                                                           round(end-start, 2)))\n",
    "        sys.stdout.flush()        \n",
    "    print(\"Training Done.\")\n",
    "    print(f\"Saved model in: {weight_file}\")\n",
    "    \n",
    "def get_experimental_result(model, my_dictBank):\n",
    "    HR = []\n",
    "    NDCG = []\n",
    "    model.eval()\n",
    "    item_list = df_T.deal_index.unique()\n",
    "    all_users_local, all_items = model.LocalGCLayers()\n",
    "    all_users_global, all_clusters = model.GlobalGCLayers(1)\n",
    "    \n",
    "    for i in range(10):\n",
    "        np.random.seed(i*7) \n",
    "        condidate_item = np.random.choice(item_list, 200, replace=False)\n",
    "\n",
    "        pred_reclist = {}\n",
    "        item_matrix = []\n",
    "        for index in tqdm(range(len(my_dictBank.t_u))):\n",
    "            u = my_dictBank.t_u[index]\n",
    "            u_condidate_item = np.setdiff1d(condidate_item, dict_interactions[u])\n",
    "            u_condidate_item = np.random.choice(u_condidate_item, 99, replace=False)\n",
    "            u_condidate_item = np.union1d(u_condidate_item, dict_interactions[u][-1:])\n",
    "            item_matrix.append(u_condidate_item)\n",
    "        v = torch.LongTensor(item_matrix)\n",
    "        v = v.t()\n",
    "        pred_result = []\n",
    "\n",
    "        for j in tqdm(range(100)):\n",
    "            y = model(torch.LongTensor(my_dictBank.t_u), v[j])\n",
    "            pred_result.append(list(y.data))\n",
    "\n",
    "        result = np.array(pred_result).T\n",
    "        pred_reclist = {}\n",
    "        for h in range(len(my_dictBank.t_u)):\n",
    "            pred_score = dict(zip(item_matrix[h], result[h]))\n",
    "            pred_score = sorted(pred_score.items(),key = lambda x:x[1],reverse = True)\n",
    "            for k in range(100):\n",
    "                pred_score[k] = pred_score[k][0]   \n",
    "            pred_reclist[my_dictBank.t_u[h]] = pred_score\n",
    "\n",
    "        hit_rite, ndcg = Evaluation(pred_reclist, my_dictBank.t_v, my_dictBank.t_u, [1,5])\n",
    "        HR.append(hit_rite)\n",
    "        NDCG.append(ndcg)\n",
    "        print(\"HR: {0}\".format(hit_rite))\n",
    "        print(\"NDCG: {0}\".format(ndcg))\n",
    "    \n",
    "    print(f\"HR@1, HR@5: \", end=\" \")\n",
    "    output_result(HR)\n",
    "    print()\n",
    "    print(f\"NDCG@1, NDCG@5:\", end=\" \")\n",
    "    output_result(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0863428a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T05:46:14.248886Z",
     "start_time": "2022-05-19T05:46:12.641223Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment scenario: MLtoAM\n",
      "Source domain file: Rating_MLasS.csv\n",
      "Target domain file:Rating_AmzMasT.csv\n",
      "n_users:8566, m_items:6752, n=inter.:39696\n"
     ]
    }
   ],
   "source": [
    "data_path = './Datasets/'\n",
    "model_file = \"./Models/\"\n",
    "Expe_scenarios = [\"MLtoAM\", \"AMtoML\"]\n",
    "source_file = [\"Rating_MLasS.csv\", \"Rating_AmzMasS.csv\"]\n",
    "target_file = [\"Rating_AmzMasT.csv\", \"Rating_MLasT.csv\"]\n",
    "\n",
    "Expe_index = 0\n",
    "\n",
    "print(\"Experiment scenario: \"+ Expe_scenarios[Expe_index])\n",
    "print(\"Source domain file: \"+ source_file[Expe_index])\n",
    "print(\"Target domain file:\" + target_file[Expe_index])\n",
    "\n",
    "df_S = pd.read_csv(data_path+ source_file[Expe_index])\n",
    "df_T = pd.read_csv(data_path+ target_file[Expe_index])\n",
    "\n",
    "'''\n",
    "---------------------------------------------------------------\n",
    "|Adding the following code when inversing source and target. e.g.(AM=>ML)\n",
    "|\n",
    "|\n",
    "|df_S = df_S[[\"account_id\", \"deal_id\"]]\n",
    "|df_S.columns =[\"userId\", \"movieId\"]\n",
    "|\n",
    "|df_T = df_T[[\"userId\", \"movieId\"]]\n",
    "|df_T.columns =[\"account_id\", \"deal_id\"]\n",
    "---------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "source_name = Expe_scenarios[Expe_index][:2]\n",
    "target_name = Expe_scenarios[Expe_index][-2:]\n",
    "\n",
    "model_file = model_file = f\"./Models/{source_name}to{target_name}/\"\n",
    "\n",
    "dict_path = './Dictionary/'\n",
    "dict_itemId2Cluster_S = np.load(dict_path + f\"{source_name}to{target_name}/Dict_item2cluster_{source_name}asS.npy\", allow_pickle=True).item()\n",
    "dict_itemId2Cluster_T = np.load(dict_path + f\"{source_name}to{target_name}/Dict_item2cluster_{target_name}asT.npy\", allow_pickle=True).item()\n",
    "dict_cluster2vec = np.load(dict_path + f\"{source_name}to{target_name}/Dict_cluster2vec_{source_name}to{target_name}.npy\", allow_pickle=True).item()\n",
    "\n",
    "dict_item2vec_t = np.load(dict_path + f'{source_name}to{target_name}/Dict_item2vec_{target_name}asT.npy', allow_pickle=True).item()\n",
    "\n",
    "df_S[\"cluster\"] = df_S.movieId.map(lambda x: dict_itemId2Cluster_S[x])\n",
    "df_T[\"cluster\"] = df_T.deal_id.map(lambda x: dict_itemId2Cluster_T[x])\n",
    "\n",
    "dict_item_id2index = dict(zip(df_T.deal_id.unique(), np.arange(len(df_T.deal_id.unique()))))\n",
    "dict_user_id2index = dict(zip(df_T.account_id.unique(), np.arange(len(df_T.account_id.unique()))))\n",
    "dict_user_id2index_S = dict(zip(df_S.userId.unique(), np.arange(len(df_T.account_id.unique()), len(df_S.userId.unique()) + len(df_T.account_id.unique()))))\n",
    "dict_itemIndex2Cluster_T = dict(zip(dict_item_id2index.values(), [dict_itemId2Cluster_T[x] for x in dict_item_id2index.keys()]))\n",
    "\n",
    "vec_matrix = [dict_item2vec_t[deal_id] for deal_id in df_T.deal_id.unique()]\n",
    "dict_ItemIndex2vec = dict(zip(np.arange(len(df_T.deal_id.unique())), vec_matrix))\n",
    "\n",
    "df_T[\"account_index\"] = df_T.account_id.map(lambda x: dict_user_id2index[x])\n",
    "df_T[\"deal_index\"] = df_T.deal_id.map(lambda x: dict_item_id2index[x])\n",
    "df_S[\"account_index\"] = df_S.userId.map(lambda x: dict_user_id2index_S[x])\n",
    "\n",
    "dict_interactions = dict(df_T.groupby(df_T[\"account_index\"])[\"deal_index\"].apply(ToList))\n",
    "dict_interactions_c = dict(df_T.groupby(df_T[\"account_index\"])[\"cluster\"].apply(ToList))\n",
    "\n",
    "\n",
    "n_users = len(df_T.account_index.unique())\n",
    "m_items = len(df_T.deal_index.unique())\n",
    "n_inters = df_T.shape[0]\n",
    "print(f\"n_users:{n_users}, m_items:{m_items}, n=inter.:{df_T.shape[0]}\")\n",
    "\n",
    "\n",
    "#UINet = csr_matrix((np.ones(len(tr_u)), (tr_u, tr_v)), shape=(n_users, m_items))\n",
    "\n",
    "#u_edge = np.concatenate([tr_u, df_S.account_index.values])\n",
    "#i_edge = np.concatenate([[dict_itemIndex2Cluster_T[i] for i in tr_v], df_S.cluster.values])\n",
    "#UCNet = csr_matrix((np.concatenate([np.ones(len(tr_u)), np.ones(len(df_S.account_index.values))]), (u_edge, i_edge)), shape=(u_edge.max()+1, 200))\n",
    "#n_u_c, n_i_c, n_u_g, n_c_g = n_users, m_items, u_edge, config[\"num_cluster\"]\n",
    "\n",
    "my_dictBank = DataBank(dict_itemId2Cluster_S, \n",
    "                dict_itemId2Cluster_T,\n",
    "                dict_item_id2index,\n",
    "                dict_user_id2index,\n",
    "                dict_user_id2index_S, \n",
    "                dict_itemIndex2Cluster_T,\n",
    "                dict_cluster2vec,\n",
    "                dict_item2vec_t,\n",
    "                dict_ItemIndex2vec,\n",
    "                dict_interactions,\n",
    "                dict_interactions_c)\n",
    "\n",
    "UINet = csr_matrix((np.ones(len(my_dictBank.tr_u)), (my_dictBank.tr_u, my_dictBank.tr_v)), shape=(n_users, m_items))\n",
    "\n",
    "u_edge = np.concatenate([my_dictBank.tr_u, df_S.account_index.values])\n",
    "i_edge = np.concatenate([[my_dictBank.dict_itemIndex2Cluster_T[i] for i in my_dictBank.tr_v], df_S.cluster.values])\n",
    "UCNet = csr_matrix((np.concatenate([np.ones(len(my_dictBank.tr_u)), np.ones(len(df_S.account_index.values))]), (u_edge, i_edge)), shape=(u_edge.max()+1, 200))\n",
    "n_u_c, n_i_c, n_u_g, n_c_g = n_users, m_items, u_edge, config[\"num_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ded890c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T06:04:39.933104Z",
     "start_time": "2022-05-19T05:46:24.298971Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lizhi/SCDGN/models.py:227: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] hr:0.019378939995330375, ndcg:0.009082842850428244\n",
      " ||epoch:9||loss:0.44730797021285346||pre_loss:0.12534848276687705||reg_loss:0.1791524835254835||rec_loss:0.13876207885534866||res_loss:0.004044931614771485||time:4.477\n",
      "[TEST] hr:0.11370534671958907, ndcg:0.08134724570882965\n",
      " ||epoch:19||loss:0.37481281679609546||pre_loss:0.07880305952352026||reg_loss:0.21505822630032248||rec_loss:0.07618432411033174||res_loss:0.004767207064382408||time:4.47\n",
      "[TEST] hr:0.12211067009105767, ndcg:0.09088321893057477\n",
      " ||epoch:29||loss:0.3681427020093669||pre_loss:0.06707359251120816||reg_loss:0.22105901655943497||rec_loss:0.07516724616289139||res_loss:0.004842845945740523||time:4.5754\n",
      "[TEST] hr:0.13436843334111603, ndcg:0.09539948668684037\n",
      " ||epoch:39||loss:0.3626092607560365||pre_loss:0.06458504886730858||reg_loss:0.22314490053964697||rec_loss:0.06998750437860904||res_loss:0.00489180522930363||time:4.499\n",
      "[TEST] hr:0.13425169273873452, ndcg:0.0976776627991439\n",
      " ||epoch:49||loss:0.3590261003245478||pre_loss:0.06306247737096704||reg_loss:0.22197159995203433||rec_loss:0.06915144444159839||res_loss:0.004840577405917904||time:4.487\n",
      "[TEST] hr:0.13868783562923184, ndcg:0.0985073465039574\n",
      " ||epoch:59||loss:0.35717280921728717||pre_loss:0.060286959066339164||reg_loss:0.2230331768160281||rec_loss:0.06899953568759172||res_loss:0.004853139226527318||time:4.47\n",
      "[TEST] hr:0.1392715386411394, ndcg:0.09862317804130047\n",
      " ||epoch:69||loss:0.35699247666027234||pre_loss:0.05985898411144381||reg_loss:0.22342823510584625||rec_loss:0.06889341010347656||res_loss:0.004811849546335314||time:4.466\n",
      "[TEST] hr:0.14067242586971748, ndcg:0.09911477193432146\n",
      " ||epoch:79||loss:0.34802443307379016||pre_loss:0.06010536833301834||reg_loss:0.22331293575141742||rec_loss:0.059804234815680465||res_loss:0.004801895145488822||time:4.45\n",
      "[TEST] hr:0.13845435442446882, ndcg:0.09956178372965113\n",
      " ||epoch:89||loss:0.36993587146634643||pre_loss:0.05671130622858587||reg_loss:0.22817242793414905||rec_loss:0.08011266767330792||res_loss:0.004939471371471882||time:4.567\n",
      "[TEST] hr:0.13997198225542845, ndcg:0.09985933573086121\n",
      " ||epoch:99||loss:0.3609675829825194||pre_loss:0.058808587815450585||reg_loss:0.23023012280464172||rec_loss:0.06702055215187695||res_loss:0.0049083217897492905||time:4.57\n",
      "[TEST] hr:0.14113938827924352, ndcg:0.10073147868044113\n",
      " ||epoch:109||loss:0.35473337380782416||pre_loss:0.05740956152262895||reg_loss:0.22556951058947522||rec_loss:0.06694477019102676||res_loss:0.004809527637679939||time:4.476\n",
      "[TEST] hr:0.13868783562923184, ndcg:0.09982504824335492\n",
      " ||epoch:119||loss:0.3616453486940135||pre_loss:0.05651323756446009||reg_loss:0.23124063468497733||rec_loss:0.06898178629901099||res_loss:0.004909690246795831||time:4.476\n",
      "[TEST] hr:0.14067242586971748, ndcg:0.1000781997201489\n",
      " ||epoch:129||loss:0.361294598683067||pre_loss:0.056792791122975556||reg_loss:0.22852300042691437||rec_loss:0.07116502912148186||res_loss:0.004813774914035331||time:4.477\n",
      "[TEST] hr:0.13903805743637637, ndcg:0.0992018591538591\n",
      " ||epoch:139||loss:0.35790700497834577||pre_loss:0.05707092226847359||reg_loss:0.2279610944830853||rec_loss:0.0680888220667839||res_loss:0.00478616458080385||time:4.53477\n",
      "[TEST] hr:0.14113938827924352, ndcg:0.10129018255497343\n",
      " ||epoch:149||loss:0.3522233574286751||pre_loss:0.057075660675764084||reg_loss:0.22943344517894412||rec_loss:0.06089996303553167||res_loss:0.0048142854205292206||time:4.57\n",
      "[TEST] hr:0.14289049731496614, ndcg:0.10112869912133836\n",
      " ||epoch:159||loss:0.35672544396441913||pre_loss:0.05543890725011411||reg_loss:0.22962013923603555||rec_loss:0.06689848459285239||res_loss:0.004767907439204661||time:4.466\n",
      "[TEST] hr:0.1424235349054401, ndcg:0.10107528067368915\n",
      " ||epoch:169||loss:0.3573155999183655||pre_loss:0.056289492579905884||reg_loss:0.22931658638560254||rec_loss:0.06697430817977242||res_loss:0.004735213522191929||time:4.56\n",
      "[TEST] hr:0.13997198225542845, ndcg:0.09935034634724628\n",
      " ||epoch:179||loss:0.36183826690134796||pre_loss:0.055402541938035385||reg_loss:0.23381449800470602||rec_loss:0.06784720799845198||res_loss:0.004774013696157414||time:4.47\n",
      "[TEST] hr:0.141022647676862, ndcg:0.10011552152291282\n",
      " ||epoch:189||loss:0.35854154436484625||pre_loss:0.056311077559771744||reg_loss:0.2307035514841909||rec_loss:0.06678101031676582||res_loss:0.004745904275256655||time:4.49\n",
      "[TEST] hr:0.14160635068876956, ndcg:0.10046824051679017\n",
      " ||epoch:199||loss:0.3580307779104813||pre_loss:0.05470657267648241||reg_loss:0.2341064162876295||rec_loss:0.06447295536813528||res_loss:0.004744831006973982||time:4.46672\n",
      "[TEST] hr:0.14125612888162503, ndcg:0.10097136750451645\n",
      " ||epoch:209||loss:0.3561499079932337||pre_loss:0.05649972966183787||reg_loss:0.23129564394121585||rec_loss:0.06364631782407346||res_loss:0.004708210532755956||time:4.5657\n",
      "[TEST] hr:0.14219005370067708, ndcg:0.10092342366172495\n",
      " ||epoch:219||loss:0.35237132466357685||pre_loss:0.0557768134319264||reg_loss:0.23261771318705185||rec_loss:0.05928767569687055||res_loss:0.004689117407669191||time:4.4858\n",
      "[TEST] hr:0.14137286948400654, ndcg:0.1010110250304506\n",
      "Training Done.\n",
      "Saved model in: ./Models/MLtoAM/MLtoAM-SCDGN_retrained.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12739.57it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.1802474900770488, 0.2679196824655615]\n",
      "NDCG: [0.16637396513232833, 0.20419099529630638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12710.58it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.1873686668223208, 0.2676862012607985]\n",
      "NDCG: [0.1720302355169777, 0.20634340136345652]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12702.77it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.17978052766752275, 0.25986458090123743]\n",
      "NDCG: [0.16538997694846488, 0.19996339647034578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12768.63it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.1898202194723325, 0.2646509455988793]\n",
      "NDCG: [0.175946694527612, 0.20813321319245412]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12762.05it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.1772122344151296, 0.25881391547980387]\n",
      "NDCG: [0.16239082888412387, 0.19756730507947062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12793.08it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.176161568993696, 0.2563623628297922]\n",
      "NDCG: [0.16142633442507986, 0.1955403838199682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12673.22it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.17441045995797338, 0.2662853140322204]\n",
      "NDCG: [0.15752095132961802, 0.19672059893482843]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12665.22it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.1887695540508989, 0.2661685734298389]\n",
      "NDCG: [0.17304335341480273, 0.20615115345651625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12682.09it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.18013074947466728, 0.2548447349988326]\n",
      "NDCG: [0.16647265193592073, 0.1984678470389798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8566/8566 [00:00<00:00, 12633.89it/s]\n",
      "100%|██████████| 100/100 [00:07<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: [0.16647209899603083, 0.24725659584403456]\n",
      "NDCG: [0.15264165953250514, 0.18733280345696643]\n",
      "HR@1, HR@5:  0.18 ± 0.005   0.261 ± 0.005   \n",
      "NDCG@1, NDCG@5: 0.165 ± 0.005   0.2 ± 0.005   "
     ]
    }
   ],
   "source": [
    "'''\n",
    " -------------------------------------------------------------------------------\n",
    "| Set congif[\"pretrained_model\"] == 0 when re-training the SCDGN model.|\n",
    " -------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "config[\"pretrained_model\"] = 1\n",
    "if config[\"pretrained_model\"]:\n",
    "    weight_file = model_file + f\"{source_name}to{target_name}-SCDGN.pth.tar\"\n",
    "    Recmodel = SCDGN(n_u_c, n_i_c, n_u_g, n_c_g, UINet, UCNet, my_dictBank, config)\n",
    "    Recmodel.load_state_dict(torch.load(weight_file))\n",
    "else:\n",
    "    Recmodel = SCDGN(n_u_c, n_i_c, n_u_g, n_c_g, UINet, UCNet, my_dictBank, config)\n",
    "    train(config, my_dictBank, model_file)\n",
    "\n",
    "get_experimental_result(Recmodel, my_dictBank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245d929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.1.0",
   "language": "python",
   "name": "torch_1.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
